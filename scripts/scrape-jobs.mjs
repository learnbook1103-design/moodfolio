// scripts/scrape-jobs.mjs
// ES Module ë²„ì „ (.mjs í™•ìž¥ìž)

import { JobScraper } from '../lib/scrapers/job-scraper.js';
import { DataCleaner } from '../lib/data-pipeline/cleaner.js';
import { DataAggregator } from '../lib/data-pipeline/aggregator.js';
import { createClient } from '@supabase/supabase-js';

// Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

if (!supabaseUrl || !supabaseKey) {
    console.error('âŒ Supabase credentials not found in environment variables');
    console.error('Please check .env.local file');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

async function main() {
    const scraper = new JobScraper();
    const cleaner = new DataCleaner();
    const aggregator = new DataAggregator();

    const jobTypes = ['developer', 'designer', 'marketer', 'service'];
    const targetPerSource = 25;

    console.log('ðŸš€ Starting job scraping...\n');

    for (const jobType of jobTypes) {
        console.log(`\nðŸ“‹ Processing ${jobType}...`);

        let allJobs = [];

        // 1. ì›í‹°ë“œì—ì„œ ìˆ˜ì§‘
        console.log(`  Scraping from Wanted...`);
        try {
            const wantedJobs = await scraper.scrapeWanted(jobType, targetPerSource);
            allJobs.push(...wantedJobs);
        } catch (error) {
            console.error(`  âš ï¸ Wanted scraping failed:`, error.message);
        }

        // 2. ì‚¬ëžŒì¸ì—ì„œ ìˆ˜ì§‘
        console.log(`  Scraping from Saramin...`);
        try {
            const saraminJobs = await scraper.scrapeSaramin(jobType, targetPerSource);
            allJobs.push(...saraminJobs);
        } catch (error) {
            console.error(`  âš ï¸ Saramin scraping failed:`, error.message);
        }

        if (allJobs.length === 0) {
            console.log(`  âš ï¸ No jobs collected for ${jobType}, skipping...`);
            continue;
        }

        // 3. ë°ì´í„° ì •ì œ
        console.log(`  Cleaning ${allJobs.length} jobs...`);
        const cleanedJobs = allJobs.map(job => cleaner.cleanJobPosting(job));

        // 4. ì¤‘ë³µ ì œê±°
        const uniqueJobs = cleaner.deduplicateJobs(cleanedJobs);
        console.log(`  After deduplication: ${uniqueJobs.length} jobs`);

        // 5. ìœ íš¨ì„± ê²€ì¦
        const validJobs = uniqueJobs.filter(job => {
            const validation = cleaner.validateJobPosting(job);
            if (!validation.isValid) {
                console.log(`  âš ï¸ Invalid job: ${validation.errors.join(', ')}`);
            }
            return validation.isValid;
        });

        console.log(`  Valid jobs: ${validJobs.length}`);

        // 6. Supabaseì— ì €ìž¥
        if (validJobs.length > 0) {
            const { data, error } = await supabase
                .from('job_postings')
                .upsert(validJobs, {
                    onConflict: 'job_id',
                    ignoreDuplicates: false
                });

            if (error) {
                console.error(`  âŒ Error saving to Supabase:`, error.message);
            } else {
                console.log(`  âœ… Saved ${validJobs.length} jobs to database`);
            }
        }

        // 7. ì¸ì‚¬ì´íŠ¸ ì§‘ê³„
        console.log(`  Aggregating insights...`);
        try {
            await aggregator.aggregateInsights(jobType);
        } catch (error) {
            console.error(`  âš ï¸ Aggregation failed:`, error.message);
        }

        // 8. íŠ¸ë Œë“œ ê³„ì‚°
        console.log(`  Calculating trends...`);
        try {
            await aggregator.calculateWeeklyTrends(jobType);
        } catch (error) {
            console.error(`  âš ï¸ Trend calculation failed:`, error.message);
        }

        console.log(`  âœ… Completed ${jobType}\n`);

        // Rate limiting between job types
        await new Promise(resolve => setTimeout(resolve, 2000));
    }

    console.log('\nðŸŽ‰ All done! Summary:');

    // ìµœì¢… í†µê³„
    for (const jobType of jobTypes) {
        const { count } = await supabase
            .from('job_postings')
            .select('*', { count: 'exact', head: true })
            .eq('job_type', jobType);

        const { data: insights } = await supabase
            .from('market_insights_cache')
            .select('sample_size, data_quality_score')
            .eq('job_type', jobType)
            .single();

        console.log(`  ${jobType}: ${count} jobs, quality score: ${insights?.data_quality_score?.toFixed(2) || 'N/A'}`);
    }
}

// ì‹¤í–‰
main().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
});
